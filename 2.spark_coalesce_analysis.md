# La fonction coalesce en Apache Spark

## Introduction

La fonction `coalesce` est une transformation Spark qui permet de réduire le nombre de partitions d'un RDD de manière efficace. Contrairement à `repartition`, `coalesce` évite un shuffle complet des données en fusionnant simplement les partitions existantes, ce qui en fait une opération plus performante pour la réduction du nombre de partitions.

## Signature de la fonction

```scala
def coalesce(numPartitions: Int, shuffle: Boolean = false): RDD[T]
```

- `numPartitions` : Le nombre cible de partitions (doit être ≤ au nombre actuel)
- `shuffle` : Si `true`, permet d'augmenter le nombre de partitions (par défaut `false`)

## Comment ça fonctionne

1. **Fusion de partitions** : `coalesce` combine plusieurs partitions existantes en une seule
2. **Pas de shuffle par défaut** : Les données ne sont pas redistribuées sur le réseau
3. **Optimisation des performances** : Réduit le parallélisme mais améliore l'efficacité des opérations suivantes

## Exemples pratiques

### Exemple 1 : Réduction basique du nombre de partitions

```scala
import org.apache.spark.{SparkConf, SparkContext}

val conf = new SparkConf().setAppName("CoalesceExample").setMaster("local[*]")
val sc = new SparkContext(conf)

// Création d'un RDD avec 8 partitions
val numbers = sc.parallelize(1 to 1000, 8)
println(s"Partitions initiales: ${numbers.getNumPartitions}")

// Réduction à 3 partitions avec coalesce
val coalescedNumbers = numbers.coalesce(3)
println(s"Partitions après coalesce: ${coalescedNumbers.getNumPartitions}")

// Vérification de la distribution des données
coalescedNumbers.mapPartitionsWithIndex { (index, iter) =>
  Iterator((index, iter.size))
}.collect().foreach { case (partitionId, count) =>
  println(s"Partition $partitionId: $count éléments")
}
```

**Résultat :**
```
Partitions initiales: 8
Partitions après coalesce: 3
Partition 0: 250 éléments
Partition 1: 375 éléments
Partition 2: 375 éléments
```

### Exemple 2 : Optimisation avant sauvegarde

```scala
// Lecture d'un large dataset
val largeDataset = sc.textFile("hdfs://path/to/large/files/*")
println(s"Partitions après lecture: ${largeDataset.getNumPartitions}")

// Traitement des données
val processedData = largeDataset
  .filter(line => line.nonEmpty)
  .map(line => line.toUpperCase)
  .filter(line => line.contains("ERROR"))

println(s"Partitions après traitement: ${processedData.getNumPartitions}")

// Optimisation avant sauvegarde pour éviter de nombreux petits fichiers
val optimizedData = processedData.coalesce(10)
println(s"Partitions optimisées: ${optimizedData.getNumPartitions}")

// Sauvegarde (créera seulement 10 fichiers au lieu de potentiellement des centaines)
// optimizedData.saveAsTextFile("hdfs://path/to/output")
```

### Exemple 3 : Gestion des données après filtrage

```scala
// Dataset initial avec beaucoup de partitions
val salesData = sc.parallelize(Seq(
  ("2023-01", "Product A", 1000),
  ("2023-01", "Product B", 1500),
  ("2023-02", "Product A", 1200),
  ("2023-02", "Product C", 800),
  ("2023-03", "Product A", 900),
  ("2023-03", "Product B", 1100)
), 20) // 20 partitions pour peu de données

println(s"Partitions initiales: ${salesData.getNumPartitions}")

// Filtrage qui réduit drastiquement les données
val filteredSales = salesData.filter(_._2 == "Product A")
println(s"Données après filtrage: ${filteredSales.count()}")

// Beaucoup de partitions vides ou presque vides
filteredSales.mapPartitionsWithIndex { (index, iter) =>
  val count = iter.size
  if (count > 0) Iterator((index, count)) else Iterator.empty
}.collect().foreach { case (partitionId, count) =>
  println(s"Partition $partitionId: $count éléments")
}

// Optimisation avec coalesce
val optimizedSales = filteredSales.coalesce(2)
println(s"Partitions optimisées: ${optimizedSales.getNumPartitions}")

optimizedSales.mapPartitionsWithIndex { (index, iter) =>
  Iterator((index, iter.size))
}.collect().foreach { case (partitionId, count) =>
  println(s"Partition optimisée $partitionId: $count éléments")
}
```

**Résultat :**
```
Partitions initiales: 20
Données après filtrage: 3
Partition 2: 1 éléments
Partition 8: 1 éléments
Partition 14: 1 éléments
Partitions optimisées: 2
Partition optimisée 0: 2 éléments
Partition optimisée 1: 1 éléments
```

## Comparaison : coalesce vs repartition

### Exemple 4 : Performance et comportement

```scala
import java.time.Instant

val testData = sc.parallelize(1 to 100000, 100)

// Test avec coalesce (pas de shuffle)
val startCoalesce = Instant.now()
val coalescedData = testData.coalesce(10)
coalescedData.count() // Action pour déclencher l'exécution
val endCoalesce = Instant.now()

// Test avec repartition (avec shuffle)
val startRepartition = Instant.now()
val repartitionedData = testData.repartition(10)
repartitionedData.count() // Action pour déclencher l'exécution
val endRepartition = Instant.now()

println(s"Temps coalesce: ${java.time.Duration.between(startCoalesce, endCoalesce).toMillis()} ms")
println(s"Temps repartition: ${java.time.Duration.between(startRepartition, endRepartition).toMillis()} ms")

// Vérification de la distribution
println("\nDistribution avec coalesce:")
coalescedData.mapPartitionsWithIndex { (index, iter) =>
  Iterator((index, iter.size))
}.collect().sortBy(_._1).foreach { case (partitionId, count) =>
  println(s"Partition $partitionId: $count éléments")
}

println("\nDistribution avec repartition:")
repartitionedData.mapPartitionsWithIndex { (index, iter) =>
  Iterator((index, iter.size))
}.collect().sortBy(_._1).foreach { case (partitionId, count) =>
  println(s"Partition $partitionId: $count éléments")
}
```

## Cas d'usage avancés

### Exemple 5 : Pipeline de traitement avec optimisation

```scala
// Simulation d'un pipeline ETL
val rawData = sc.textFile("input/*", 200) // 200 partitions initiales

val cleanedData = rawData
  .filter(_.trim.nonEmpty)                    // Supprime les lignes vides
  .filter(!_.startsWith("#"))                 // Supprime les commentaires
  .map(_.toLowerCase)                         // Normalisation

println(s"Après nettoyage: ${cleanedData.getNumPartitions} partitions")

// Après filtrage, beaucoup de partitions peuvent être vides
val validRecords = cleanedData.filter(_.contains("valid"))

// Comptage par partition pour voir la distribution
val partitionCounts = validRecords.mapPartitionsWithIndex { (index, iter) =>
  Iterator((index, iter.size))
}.collect()

val nonEmptyPartitions = partitionCounts.filter(_._2 > 0).length
println(s"Partitions non vides: $nonEmptyPartitions sur ${validRecords.getNumPartitions}")

// Optimisation intelligente
val optimalPartitions = Math.max(nonEmptyPartitions / 2, 1)
val optimizedData = validRecords.coalesce(optimalPartitions)

println(s"Partitions optimisées: ${optimizedData.getNumPartitions}")

// Traitement final plus efficace
val finalResult = optimizedData
  .map(record => processRecord(record))
  .filter(_.isDefined)
  .map(_.get)

// Fonction helper
def processRecord(record: String): Option[String] = {
  if (record.length > 10) Some(record.toUpperCase) else None
}
```

### Exemple 6 : Gestion des données géographiques

```scala
case class SalesRecord(region: String, product: String, amount: Double)

val allSales = sc.parallelize(Seq(
  SalesRecord("Europe", "Laptop", 1000),
  SalesRecord("Europe", "Mouse", 50),
  SalesRecord("Asia", "Laptop", 1200),
  SalesRecord("Americas", "Keyboard", 80),
  SalesRecord("Europe", "Monitor", 300)
), 50) // Beaucoup de partitions pour peu de données

// Analyse par région
val regions = List("Europe", "Asia", "Americas")

regions.foreach { region =>
  val regionData = allSales.filter(_.region == region)
  val count = regionData.count()
  
  println(s"\n=== Région: $region ===")
  println(s"Nombre d'enregistrements: $count")
  println(s"Partitions avant coalesce: ${regionData.getNumPartitions}")
  
  // Optimisation basée sur la quantité de données
  val optimalPartitions = Math.max((count / 100).toInt, 1)
  val optimizedRegionData = regionData.coalesce(optimalPartitions)
  
  println(s"Partitions après coalesce: ${optimizedRegionData.getNumPartitions}")
  
  // Calcul des statistiques
  val totalSales = optimizedRegionData.map(_.amount).sum()
  val avgSales = totalSales / count
  
  println(f"Total des ventes: $$${totalSales}%.2f")
  println(f"Moyenne par vente: $$${avgSales}%.2f")
}
```

## Cas particuliers et pièges à éviter

### Exemple 7 : Quand coalesce peut poser problème

```scala
// Problème 1: Distribution inégale des données
val skewedData = sc.parallelize(
  (1 to 10).map(i => (i % 3, s"data_$i")) ++
  (1 to 1000).map(i => (0, s"bulk_data_$i")), // Beaucoup de données avec clé 0
  10
)

println("Distribution avant coalesce:")
skewedData.mapPartitionsWithIndex { (index, iter) =>
  Iterator((index, iter.size))
}.collect().foreach { case (partitionId, count) =>
  println(s"Partition $partitionId: $count éléments")
}

// Coalesce peut créer des partitions très déséquilibrées
val coalescedSkewed = skewedData.coalesce(3)

println("\nDistribution après coalesce:")
coalescedSkewed.mapPartitionsWithIndex { (index, iter) =>
  Iterator((index, iter.size))
}.collect().foreach { case (partitionId, count) =>
  println(s"Partition $partitionId: $count éléments")
}

// Solution: utiliser repartition pour un meilleur équilibrage si nécessaire
val rebalanced = skewedData.repartition(3)
println("\nDistribution après repartition:")
rebalanced.mapPartitionsWithIndex { (index, iter) =>
  Iterator((index, iter.size))
}.collect().foreach { case (partitionId, count) =>
  println(s"Partition $partitionId: $count éléments")
}
```

### Exemple 8 : Coalesce avec shuffle pour augmenter les partitions

```scala
val smallData = sc.parallelize(1 to 100, 2)
println(s"Partitions initiales: ${smallData.getNumPartitions}")

// Tentative d'augmentation sans shuffle (ne fonctionne pas)
val attemptIncrease = smallData.coalesce(5)
println(s"Après coalesce(5, false): ${attemptIncrease.getNumPartitions}")

// Augmentation avec shuffle
val increasedWithShuffle = smallData.coalesce(5, shuffle = true)
println(s"Après coalesce(5, true): ${increasedWithShuffle.getNumPartitions}")

// Note: coalesce(n, true) est équivalent à repartition(n)
val repartitioned = smallData.repartition(5)
println(s"Après repartition(5): ${repartitioned.getNumPartitions}")
```

## Bonnes pratiques et recommandations

### 1. Quand utiliser coalesce

```scala
// ✅ Bon usage: après filtrage qui réduit drastiquement les données
val filtered = largeRDD.filter(condition)
val optimized = filtered.coalesce(optimalPartitionCount)

// ✅ Bon usage: avant sauvegarde pour éviter de nombreux petits fichiers
val readyToSave = processedData.coalesce(10)
readyToSave.saveAsTextFile("output")

// ✅ Bon usage: optimisation de pipeline
val pipeline = rawData
  .filter(cleaningCondition)
  .coalesce(50)  // Réduction intermédiaire
  .map(expensiveTransformation)
  .coalesce(10)  // Réduction finale avant sauvegarde
```

### 2. Calcul du nombre optimal de partitions

```scala
def calculateOptimalPartitions(rdd: RDD[_], targetSizePerPartitionMB: Int = 128): Int = {
  val totalSize = rdd.map(_.toString.getBytes.length).sum()
  val totalSizeMB = totalSize / (1024 * 1024)
  val optimalPartitions = Math.max((totalSizeMB / targetSizePerPartitionMB).toInt, 1)
  
  // Ne pas dépasser le nombre de partitions actuelles avec coalesce
  Math.min(optimalPartitions, rdd.getNumPartitions)
}

// Utilisation
val data = sc.textFile("input/*")
val optimal = calculateOptimalPartitions(data)
val optimizedData = data.coalesce(optimal)
```

### 3. Monitoring et debugging

```scala
def analyzePartitionDistribution(rdd: RDD[_], name: String): Unit = {
  println(s"\n=== Analyse de $name ===")
  println(s"Nombre de partitions: ${rdd.getNumPartitions}")
  
  val distribution = rdd.mapPartitionsWithIndex { (index, iter) =>
    Iterator((index, iter.size))
  }.collect()
  
  val totalElements = distribution.map(_._2).sum
  val nonEmptyPartitions = distribution.count(_._2 > 0)
  val maxElements = if (distribution.nonEmpty) distribution.map(_._2).max else 0
  val minElements = if (distribution.nonEmpty) distribution.filter(_._2 > 0).map(_._2).min else 0
  
  println(s"Éléments totaux: $totalElements")
  println(s"Partitions non vides: $nonEmptyPartitions")
  println(s"Éléments par partition - Min: $minElements, Max: $maxElements")
  println(s"Déséquilibre: ${if (minElements > 0) maxElements.toDouble / minElements else "N/A"}")
}

// Utilisation
val originalData = sc.parallelize(1 to 1000, 50)
analyzePartitionDistribution(originalData, "Données originales")

val coalescedData = originalData.coalesce(10)
analyzePartitionDistribution(coalescedData, "Après coalesce")
```

## Avantages et inconvénients

### Avantages
- **Performance** : Pas de shuffle réseau, opération très rapide
- **Simplicité** : Facile à utiliser et à comprendre
- **Efficacité mémoire** : Réduit l'overhead des petites partitions
- **Optimisation I/O** : Réduit le nombre de fichiers de sortie

### Inconvénients
- **Distribution inégale** : Peut créer des partitions déséquilibrées
- **Limitation** : Ne peut que réduire le nombre de partitions (sans shuffle)
- **Localité** : Peut affecter la localité des données
- **Flexibilité limitée** : Moins flexible que repartition pour le rééquilibrage

## Conclusion

La fonction `coalesce` est un outil essentiel pour l'optimisation des performances Spark. Elle est particulièrement utile pour :

- **Optimiser les pipelines** après des opérations de filtrage
- **Réduire les coûts I/O** en diminuant le nombre de fichiers de sortie
- **Améliorer les performances** en réduisant l'overhead des petites partitions
- **Économiser les ressources** en évitant les shuffles inutiles

La clé du succès avec `coalesce` est de comprendre quand l'utiliser et comment calculer le nombre optimal de partitions selon votre cas d'usage spécifique. Toujours surveiller la distribution des données après l'opération pour s'assurer qu'elle reste équilibrée.