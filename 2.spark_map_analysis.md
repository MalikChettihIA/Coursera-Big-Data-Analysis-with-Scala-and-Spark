# Analyse du code : Lazy/Eager et Driver/Worker

## Code analysé
```scala
val valeurs: RDD[Double] = sc.parallelize(List(1.5, 2.7, 3.2, 4.8, 5.1))

val resultats: RDD[String] = valeurs
  .map(x => x * x)                    // Carré
  .map(x => math.sqrt(x))             // Racine carrée 
  .map(x => math.round(x * 100.0) / 100.0)  // Arrondir à 2 décimales
  .map(x => f"Valeur: $x%.2f")        // Formater en string

println("Résultats des calculs:")
resultats.collect().foreach(println)
```

## Analyse détaillée

### Ligne 1 : `val valeurs: RDD[Double] = sc.parallelize(...)`
- **Type** : **EAGER** (création d'un RDD)
- **Exécution** : **DRIVER** → **WORKERS**
- **Détail** : Le driver distribue la liste aux workers et crée les partitions

---

### Lignes 3-7 : Les transformations `map()`
```scala
val resultats: RDD[String] = valeurs
  .map(x => x * x)                    // LAZY
  .map(x => math.sqrt(x))             // LAZY
  .map(x => math.round(x * 100.0) / 100.0)  // LAZY
  .map(x => f"Valeur: $x%.2f")        // LAZY
```

- **Type** : **LAZY** (toutes les transformations)
- **Exécution** : **RIEN** n'est exécuté à ce moment !
- **Détail** : Spark construit un **graphe de calcul** (DAG) mais n'exécute rien

---

### Ligne 9 : `println("Résultats des calculs:")`
- **Type** : **EAGER** 
- **Exécution** : **DRIVER**
- **Détail** : Simple affichage sur la console du driver

---

### Ligne 10 : `resultats.collect().foreach(println)`

#### `collect()` - L'ACTION qui déclenche tout
- **Type** : **EAGER** 
- **Exécution** : 
  1. **WORKERS** : Exécutent toutes les transformations map() 
  2. **WORKERS → DRIVER** : Renvoient les résultats au driver
  3. **DRIVER** : Reçoit tous les résultats dans un Array

#### `foreach(println)` 
- **Type** : **EAGER**
- **Exécution** : **DRIVER**
- **Détail** : Affiche les résultats sur la console du driver

## Timeline d'exécution

```
Temps 0 : val valeurs = sc.parallelize(...)
         ↓
    DRIVER crée les partitions → Distribue aux WORKERS
    
Temps 1-6 : Les 4 map() sont définis
         ↓
    RIEN ne s'exécute ! Spark construit juste le DAG
    
Temps 7 : println("Résultats...")
         ↓
    DRIVER affiche le message
    
Temps 8 : resultats.collect()  ← ACTION !
         ↓
    WORKERS exécutent SIMULTANÉMENT :
    - map(x => x * x)
    - map(x => math.sqrt(x))  
    - map(x => math.round(x * 100.0) / 100.0)
    - map(x => f"Valeur: $x%.2f")
         ↓
    WORKERS → DRIVER : envoient les résultats
         ↓
    DRIVER reçoit Array[String]
         ↓
    DRIVER exécute foreach(println)
```

## Optimisations de Spark

Grâce à la lazy evaluation, Spark peut optimiser :

1. **Fusion des transformations** : Les 4 `map()` sont fusionnées en une seule passe sur les données
2. **Pipeline processing** : Chaque élément passe par tous les `map()` avant de passer au suivant
3. **Pas d'RDD intermédiaires** : Pas de stockage temporaire entre chaque `map()`

## Schéma visuel

```
DRIVER                           WORKERS
  │                               │
  ├─ sc.parallelize() ─────────→  │ Création partitions
  │                               │
  ├─ 4 x map() définitions        │ (rien n'est exécuté)
  │                               │
  ├─ println("Résultats...")      │
  │                               │
  ├─ collect() ───────────────────→│ Exécution des 4 map()
  │                               │ sur chaque partition
  │                               │
  │ ←─────────────────── Array────┤ Retour des résultats
  │                               │
  ├─ foreach(println)             │
  └─ Affichage final              │
```

## Points clés à retenir

- **Avant `collect()`** : Aucun calcul n'est fait sur les workers
- **`collect()` déclenche** : Toutes les transformations en une fois
- **Optimisation** : Spark fusionne les 4 `map()` en un seul pipeline
- **Résultats** : Tous les résultats transitent vers le driver